<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  

  
  <title>John-Yao&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="John-Yao&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="John-Yao&#39;s Blog">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="John-Yao&#39;s Blog">
  
    <link rel="alternate" href="/atom.xml" title="John-Yao&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">John-Yao&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Aboutme" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/21/Aboutme/" class="article-date">
  <time datetime="2020-08-20T16:34:12.000Z" itemprop="datePublished">2020-08-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/21/Aboutme/">Aboutme</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>My main research includes object detection, multi-object tracking, image retrieval, pedestrian reidentification. I also achieve some top rank of CVPR, ICCV and Tianchi. </p>
<h2 id="Competition-Award"><a href="#Competition-Award" class="headerlink" title="Competition Award"></a>Competition Award</h2><h3 id="Multi-Object-Tracking"><a href="#Multi-Object-Tracking" class="headerlink" title="Multi-Object-Tracking"></a>Multi-Object-Tracking</h3><ul>
<li>July 15, 2020 <a href="http://aiskyeye.com/leaderboard/" target="_blank" rel="noopener">2nd place of Visdrone 2020 Multi-Ojbect-Tracking</a></li>
<li>August 15, 2020 <a href="https://www.biendata.xyz/competition/gigavision1/final-leaderboard/" target="_blank" rel="noopener">1st place of Gigavision 2020 Pedestrian Tracking</a></li>
</ul>
<h3 id="Image-Retrieval"><a href="#Image-Retrieval" class="headerlink" title="Image Retrieval"></a>Image Retrieval</h3><ul>
<li>August 17, 2020 <a href="https://www.kaggle.com/c/landmark-retrieval-2020/leaderboard" target="_blank" rel="noopener">Gold medel of Google Landmark Retrieval</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/21/Aboutme/" data-id="cke3gzxba0000poukduii2seo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/20/hello-world/" class="article-date">
  <time datetime="2020-08-20T13:26:34.653Z" itemprop="datePublished">2020-08-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/20/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/20/hello-world/" data-id="cke3gzxbp0007poukwukzuw3h" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Data-Augmentations-in-Image-Classification" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/30/Data-Augmentations-in-Image-Classification/" class="article-date">
  <time datetime="2020-04-30T09:10:04.000Z" itemprop="datePublished">2020-04-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Image-Classification/">Image Classification</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/30/Data-Augmentations-in-Image-Classification/">Data Augmentations in Image Classification</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>​    在图像分类中，数据增强是必不可少的步骤，合适的数据增强可以增加模型的泛化能力，取得更好的分类精度。本文旨在整个在图像分类任务上最近一些比较实用的方法，并给出简单的实现过程，在具体的实验中，并不能确保哪种数据增强策略是比较理想的，需要在实际的数据中合适的选择。</p>
<p>​    本文主要涉及以下数据增强策略：</p>
<ul>
<li>Cutout<ul>
<li>DeVries, Terrance, and Graham W. Taylor. “Improved Regularization of Convolutional Neural Networks with Cutout.” arXiv preprint arXiv:1708.04552 (2017). <a href="https://arxiv.org/abs/1708.04552" target="_blank" rel="noopener">arXiv:1708.04552</a>, <a href="https://github.com/uoguelph-mlrg/Cutout" target="_blank" rel="noopener">PyTorch implementation</a></li>
</ul>
</li>
<li>RandomErase<ul>
<li>Zhong, Zhun, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. “Random Erasing Data Augmentation.” arXiv preprint arXiv:1708.04896 (2017). <a href="https://arxiv.org/abs/1708.04896" target="_blank" rel="noopener">arXiv:1708.04896</a>, <a href="https://github.com/zhunzhong07/Random-Erasing" target="_blank" rel="noopener">PyTorch implementation</a></li>
</ul>
</li>
<li>AutoAug<ul>
<li>Cubuk E D , Zoph B , Mane D , et al. AutoAugment: Learning Augmentation Policies from Data[J]. 2018.</li>
</ul>
</li>
<li>Mixup<ul>
<li>Zhang, Hongyi, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. “mixup: Beyond Empirical Risk Minimization.” In International Conference on Learning Representations (ICLR), 2017. <a href="https://openreview.net/forum?id=r1Ddp1-Rb" target="_blank" rel="noopener">link</a>, <a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noopener">arXiv:1710.09412</a></li>
<li>Zhang Z, He T, Zhang H, et al. Bag of freebies for training object detection neural networks[J]. arXiv preprint arXiv:1902.04103, 2019.</li>
</ul>
</li>
<li>Cutmix<ul>
<li>Yun, Sangdoo, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. “CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features.” arXiv preprint arXiv:1905.04899 (2019). <a href="https://arxiv.org/abs/1905.04899" target="_blank" rel="noopener">arXiv:1905.04899</a></li>
</ul>
</li>
<li>RICAP<ul>
<li>Takahashi, Ryo, Takashi Matsubara, and Kuniaki Uehara. “Data Augmentation using Random Image Cropping and Patching for Deep CNNs.” Proceedings of The 10th Asian Conference on Machine Learning (ACML), 2018. <a href="http://proceedings.mlr.press/v95/takahashi18a.html" target="_blank" rel="noopener">link</a>, <a href="https://arxiv.org/abs/1811.09030" target="_blank" rel="noopener">arXiv:1811.09030</a></li>
</ul>
</li>
</ul>
<h1 id="Cutout"><a href="#Cutout" class="headerlink" title="Cutout"></a>Cutout</h1><img src="/2020/04/30/Data-Augmentations-in-Image-Classification/cutout.png" style="zoom:100%;">

<p>​    Cutout的具体实现效果如上图所示，使用固定大小的正方形的patch在零均值化的图像上随机擦除，擦除的位置变为0. 原文指出，在超参设置上cutout的面积大小比形状更重要，并且在实验过程中发现通过按照50%的比例使用cutout和原图训练的模型往往取得更好的效果。</p>
<p>​    Cutout变种有：Dual-Cutout，RandomErase</p>
<h1 id="RandomErase"><a href="#RandomErase" class="headerlink" title="RandomErase"></a>RandomErase</h1><img src="/2020/04/30/Data-Augmentations-in-Image-Classification/RandomErase.png" style="zoom:100%;">

<p>RandomErase的具体实现效果如上图所示，对比cutout而言，引入了形状、填充值等变化，不是简单的使用方形，而是使用了不同长宽比进行擦除，擦除的填充值采用了随机值，一般实现上使用图像的均值效果差别不大。</p>
<p>RandomErase原文不仅在图像分类进行了实验，在ReID任务上也进行了比较，提分比较明显。</p>
<h1 id="AutoAug"><a href="#AutoAug" class="headerlink" title="AutoAug"></a>AutoAug</h1><p>AutoAug定义了一些涉及仿射变换、旋转等子策略，通过搜索算法在目标数据集上搜索对应得概率和幅值。在竞赛时间、数据量大、资源有限得情况下，我们可以使用Imagenet上学习得到得子策略进行增强(增强效果如下图所示)。这种增强往往并不一定有效，比如之前在我们的一个数据集上，seresnext101_32x8d使用autoaug反而掉点，但是在使用resnest101的实验中，涨幅十分明显，并且超过了最优的seresnext101_32x8d（对比没使用autoaug的配置，resnest101比seresnext101更低）。因此有时候，有必要组合多种条件进行调参。</p>
<img src="/2020/04/30/Data-Augmentations-in-Image-Classification/autoaug.png" style="zoom:100%;">

<h1 id="Mixup"><a href="#Mixup" class="headerlink" title="Mixup"></a>Mixup</h1><p>mixup会在一个batch内随机选择两张图片（A,B）进行融合，融合的权重λ从beta分布采样得到，然后对两张图像的标签分别计算损失，并使用λ，1-λ进行加权求和。具体效果可以看cutmix小节的效果图。</p>
<p>mixup在yolov3系列中检测也经常用到,具体可参考Bag of freebies for training object detection neural networks</p>
<h1 id="Cutmix"><a href="#Cutmix" class="headerlink" title="Cutmix"></a>Cutmix</h1><p>如图所示，Cutmix在具体实现上会在一个batch内随机选择两张图片（A,B）进行融合，具体的，以其中一张A作为画布，并使用（0-1）均匀分布选择融合的面积比lambda，从另外一张图片B随机裁剪与其一样长宽比的patch,随机的黏贴到A上。在loss的计算上，按照<strong>校准后</strong> 1-lambda, lambda 的比例计算对应的分类损失即可</p>
<img src="/2020/04/30/Data-Augmentations-in-Image-Classification/mixup-cutout-cumix.png" style="zoom:100%;">

<h1 id="RICAP"><a href="#RICAP" class="headerlink" title="RICAP"></a>RICAP</h1><p>RICAP全称Random Image Cropping and Patching, RICAP会在会在一个batch内随机选择四张图片（A,B,C,D）进行融合,具体地，从beta分布采样ratio_x,ratio_y，根据预定义好的图像尺寸生成中间点（w，h）,然后再随机从其他图像裁剪一块图像黏贴到对应位置，在损失函数计算上，更加采样窗口的比例进行加权求和</p>
<img src="/2020/04/30/Data-Augmentations-in-Image-Classification/ricap.png" style="zoom:100%;">

<p>ricap在检测中有个类似的应用Stitcher（<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2004.12432.pdf" target="_blank" rel="noopener">Sitcher: Feedback-driven Data Provider for Object Detection
  </a>）</p>
<h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>本文列举的数据增强并不算多，但是如何用好这些需要图像算法工程师的仔细调参，比如在我们的一个数据集中，我们进行了模型resnest和senext的对比实验，加入了autaug对resnest的提升比较大，对senext提升并不明显；在cutmix和ricap的实验中，使用小batchsize的RICAP效果更理想，使用大batchsize的cutmix效果更优，当然这可能跟数据集有关，但是不可否认的是数据增强策略和模型及其超参可能存在一定的耦合，如果是竞赛的话，可以尝试多种组合策略。</p>
<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>本文的主要参考内容如下：</p>
<ul>
<li><a href="https://github.com/hysts/pytorch_image_classification" target="_blank" rel="noopener">https://github.com/hysts/pytorch_image_classification</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/04/30/Data-Augmentations-in-Image-Classification/" data-id="cke3gzxbj0004pouk7no24h65" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Image-Classification-Data-Augmentation/">Image Classification, Data Augmentation</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-map-evaluation of object detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/13/map-evaluation of object detection/" class="article-date">
  <time datetime="2019-10-13T06:40:27.000Z" itemprop="datePublished">2019-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Ojbect-Detection/">Ojbect_Detection</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/13/map-evaluation of object detection/">Anlysis and implementation of mAP-evaluation of object detection</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>​     目标检测中衡量识别精度的常用指标是mAP（mean average precision）。多个类别物体检测中，每一个类别都可以根据recall和precision绘制一条曲线，AP就是该曲线下的面积，mAP是多个类别AP的平均值 。</p>
<h2 id="Information"><a href="#Information" class="headerlink" title="Information"></a>Information</h2><p>Code: </p>
<ul>
<li><a href="https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py" target="_blank" rel="noopener">https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py</a> </li>
<li><a href="https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py</a> </li>
</ul>
<p>Reference:</p>
<ul>
<li>目标检测中的mAP是什么含义？ - Wentao的回答 - 知乎<br><a href="https://www.zhihu.com/question/53405779/answer/419532990" target="_blank" rel="noopener">https://www.zhihu.com/question/53405779/answer/419532990</a></li>
<li>ROC，AUC，PR，AP介绍及python绘制 <a href="https://www.cnblogs.com/zf-blog/p/6734686.html" target="_blank" rel="noopener">https://www.cnblogs.com/zf-blog/p/6734686.html</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html%23SECTION00044000000000000000" target="_blank" rel="noopener">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Development Kit</a></li>
<li>用mAP衡量目标检测的性能是否科学？ - Angzz的回答 - 知乎 <a href="https://www.zhihu.com/question/337856533/answer/769453722" target="_blank" rel="noopener">https://www.zhihu.com/question/337856533/answer/769453722</a> </li>
</ul>
<h2 id="Approach-Description"><a href="#Approach-Description" class="headerlink" title="Approach Description"></a>Approach Description</h2><h3 id="mAP定义集相关概念"><a href="#mAP定义集相关概念" class="headerlink" title="mAP定义集相关概念"></a>mAP定义集相关概念</h3><ul>
<li>mAP: mean Average Precision, 即各类别AP的平均值</li>
<li>AP: PR曲线下的面积</li>
<li>PR曲线: Precision-Recall曲线</li>
<li>Precision: TP / (TP + FP)</li>
<li>Recall: TP / (TP + FN)</li>
<li>TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次）</li>
<li>FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的<strong>多余</strong>检测框的数量 （ps:多余的意思是指对一个gt预测出多个框的iou大于阈值，只考虑最大iou的 检测框）</li>
<li>FN: 没有检测到的GT的数量</li>
</ul>
<h4 id="mAP的计算方法"><a href="#mAP的计算方法" class="headerlink" title="mAP的计算方法"></a>mAP的计算方法</h4><p>​    要计算mAP必须先绘出各类别PR曲线，通过对PR曲线的面积统计得出AP。</p>
<p>​        <strong>如何采样PR曲线</strong>，VOC，COCO都采用过下面几种不同方法。</p>
<ul>
<li><p>在VOC2010以前，只需要选取当Recall &gt;= 0, 0.1, 0.2, …, 1共11个点时的<strong>Precision最大值</strong>，然后AP就是这11个Precision的平均值。</p>
</li>
<li><p>在VOC2010及以后， 假设设这一张图片M个正例，那么我们会得到M个recall值（1/M, 2/M, …, M/M）,对于每个recall值r，我们可以计算出对应（r’ &gt; r）的最大precision，然后对这M个precision值取平均即得到最后的AP值。 </p>
</li>
<li><p>COCO(pycocotools) 选取当Recall &gt;= 0, 0.01, 0.02, …, 1共101个点时的Precision最大值，然后AP就是这101个Precision的平均值。 </p>
</li>
</ul>
<p>  <strong>如何计算Precision, Recall</strong>:</p>
<p>  根据Precision的定义需要确定TP、FP、FN的值，那么如何确定这些值并且和设定recall阈值对应起来呢？</p>
<ol>
<li><p>确定iou_thres(0.5)，将pred_boxes按score排序，<strong>相同imageID</strong>下，将pred_boxes 和gt_boxes进行匹配：</p>
<ul>
<li><p>(method1) 对每个gt_box 计算与未被匹配的pred_boxes的iou，取最大iou的pred_box，若iou&gt;iou_thres则该pred_box置为TP,否则为FP</p>
</li>
<li><p>(method2，voc)对每个pred_box 计算与gt_boxes的iou,取最大iou的gt_box，若iou&gt;iou_thres且该gt_box未被匹配则将该pred_box置为TP，否则为FP</p>
<p>经过上述方法可以得到长度为len(pred_boxes)的tps/fps数组，可以用1代表对应位置为TP/FP</p>
</li>
</ul>
</li>
<li><p>对tps，fps分别进行累加，得到累加数组，第i个元素代表在第i个pred_boxes的score划分正负样本时，TP和FP的值（ps：只考虑了预测为正样本部分），于是可以得到不同score下的Precision，Recall的值，分别记为precisions,recalls。Recall的分母为len(gt_boxes)</p>
</li>
<li><p><strong>平滑处理</strong>：</p>
<ol>
<li>对precisions的每个元素，取当前位置后面所有precision的最大值</li>
</ol>
</li>
<li><p>根据确定的Recall threshold找到其在Recall的位置，并确定其precision值，相邻的recall相减并与precision值相乘，所有乘积之和就是ap</p>
</li>
</ol>
<p>note: </p>
<p>​    precision的最大值体现在如果只是简单取recall阈值下的precision那么绘制出来的PR曲线并不是单调递减的。    举例来说tps为 [0,1,0,1,1]，则累加后为：[0,1,1,2,3]，precisions为：[0,1/2,1/3/，2/4，3/5]，可以看到precision可能是波动的，PR曲线并不是单调递减的，通过平滑处理，可以保证PR曲线的单调性，有利于观察PR曲线选择合适的score阈值。</p>
<h4 id="参考第2个链接的例子理解上述过程："><a href="#参考第2个链接的例子理解上述过程：" class="headerlink" title="参考第2个链接的例子理解上述过程："></a>参考第2个链接的例子理解上述过程：</h4><p> 假设从测试集中共检测出20个例子，而测试集中共有6个正例，则PR表如下： </p>
<img src="/2019/10/13/map-evaluation of object detection/PR_table.png" style="zoom:100%;">

<p>PR波形图如下</p>
<img src="/2019/10/13/map-evaluation of object detection/PR_curve.png" style="zoom:80%;">

<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>pseudo code：给出一张图片，一个类别时的AP伪代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"># Box = Tuple[int, int, int, int]</span><br><span class="line"># [left, top, right, bottom]</span><br><span class="line"></span><br><span class="line">def IoU(box1:Box, box2:Box) -&gt; float:</span><br><span class="line">    pass</span><br><span class="line">    </span><br><span class="line">def AP(boxes:List[Box], gt_boxes:List[Box], thres:float) -&gt; float:</span><br><span class="line">    N = len(boxes)</span><br><span class="line">    M = len(gt_boxes)</span><br><span class="line">    pred_match = [0 for i in range(N)]</span><br><span class="line">    for i in range(M):</span><br><span class="line">        max_id = 0</span><br><span class="line">        max_iou = 0</span><br><span class="line">        for j in range(N):</span><br><span class="line">            if pred_match[j]==0:</span><br><span class="line">               iou = IoU(gt_boxes[i],boxes[j]) </span><br><span class="line">               if iou&gt;thres:</span><br><span class="line">                   if iou&gt;max_iou:</span><br><span class="line">                       max_id = j</span><br><span class="line">                       max_iou = iou</span><br><span class="line">       pred_match[max_id] = i+1</span><br><span class="line">   precisions = []</span><br><span class="line">   # recalls = []</span><br><span class="line">   tp = 0</span><br><span class="line">   for i in range(N):</span><br><span class="line">       if pred_match[i]!=0:</span><br><span class="line">           tp += (pred_match[i]!=0)</span><br><span class="line">           fp = N-tp</span><br><span class="line">           recall = tp/M</span><br><span class="line">           precision = tp/(i+1)</span><br><span class="line">           # recalls.append(recall)</span><br><span class="line">           precisions.append(precision)</span><br><span class="line">    # smooth</span><br><span class="line">    precisions = [0.0]+precisions+[0.0]</span><br><span class="line">    for i in range(len(precisions)-1,0,-1):</span><br><span class="line">        precisions[i-1] = max(precisions[i-1],precisions[i])</span><br><span class="line"></span><br><span class="line">    precisions = precisions[1:-1]</span><br><span class="line">    ap = [precisions[i]*1/M for i in range(len(precisions))]</span><br><span class="line">    ap = sum(ap)</span><br><span class="line">    </span><br><span class="line">    return ap</span><br></pre></td></tr></table></figure>

<h2 id="Extension"><a href="#Extension" class="headerlink" title="Extension:"></a>Extension:</h2><p>​    在训练好detection model，可以通过softnms，多尺度测试，flip测试增强等trick提升mAP, 但是基本都是通过提升recall，涨的低Precision的区域，低精度区对应用场景来说没用 。</p>
<p>​    实际应用中可以使用FPPI(False Positve Per Image), MISS Rate(行人检测常用)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/10/13/map-evaluation of object detection/" data-id="cke3gzxbr0008pouk2gfhvica" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ojbect-Detection/">Ojbect_Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Reranking" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/18/Reranking/" class="article-date">
  <time datetime="2019-09-17T16:40:27.000Z" itemprop="datePublished">2019-09-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ReID/">ReID</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/18/Reranking/">Reranking</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>​        在图像检索过程中，或者ReID(将 Re-ID看作一个检索过程时)，re-ranking是提高其准确性的关键步骤，是各大竞赛刷榜得利器。</p>
<p>​        Re-Ranking的思想基于这么一个假设：</p>
<p>​        <em>if a gallery image is similar to the probe in the k-reciprocal nearest neighbors, it is more likely to be a true match.</em></p>
<p>​        简单的解释就是，根据probe在<strong>probes+galleries</strong>搜索出来的candidate对象，根据这些candidate对象在<strong>probes+galleries</strong>选择k个nearest，如果包含你的probe，那它的可能性更大一些。</p>
<h2 id="Information"><a href="#Information" class="headerlink" title="Information"></a>Information</h2><p>Paper: (CVPR2017) Re-ranking Person Re-identification with k-reciprocal Encoding.</p>
<p>Code: </p>
<ul>
<li>(matlab) <a href="https://github.com/zhunzhong07/person-re-ranking" target="_blank" rel="noopener">https://github.com/zhunzhong07/person-re-ranking</a></li>
<li>(python cpu:代码简洁，使用堆排序加速，k reciprocal nearest neighbors没有去重)  <a href="https://github.com/layumi/Person_reID_baseline_pytorch/" target="_blank" rel="noopener">https://github.com/layumi/Person_reID_baseline_pytorch/</a></li>
<li>(pytorch gpu) <a href="https://github.com/michuanhaohao/reid-strong-baseline" target="_blank" rel="noopener">https://github.com/michuanhaohao/reid-strong-baseline</a></li>
</ul>
<p>Reference:</p>
<ul>
<li><a href="https://blog.csdn.net/lwplwf/article/details/84862054" target="_blank" rel="noopener">https://blog.csdn.net/lwplwf/article/details/84862054</a></li>
<li>谁能解释下 行人重识别reranking的原理？ - linolzhang的回答 - 知乎<br><a href="https://www.zhihu.com/question/271308170/answer/361943914" target="_blank" rel="noopener">https://www.zhihu.com/question/271308170/answer/361943914</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/36834023" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36834023</a></li>
</ul>
<h2 id="Approach-Description"><a href="#Approach-Description" class="headerlink" title="Approach Description"></a>Approach Description</h2><h3 id="K-reciprocal-Nearest-Neighbors"><a href="#K-reciprocal-Nearest-Neighbors" class="headerlink" title="K-reciprocal Nearest Neighbors"></a>K-reciprocal Nearest Neighbors</h3><p>​    回顾常规检索过程，probe(p)在galleries检索的topk({g1,g2,..,}),定义为：<img src="/2019/09/18/Reranking/top-k.png" alt></p>
<p>​    k-reciprocal nearest neighbors定义为：</p>
<p><img src="/2019/09/18/Reranking/k-reciprocal.png" alt></p>
<p>​    probe(p)在<strong>probes+galleries</strong>检索的topk的candidates对象（不包含p），如果这些candidates对象在<strong>probes+galleries</strong>选泽的topk包含了p,则该candidate与p互为top-k。</p>
<p>​    有时候probe的匹配图片不在probe的top-k之中，这时候使用下面的方法进行召回：</p>
<p><img src="/2019/09/18/Reranking/k-reciprocal-expand.png" alt></p>
<p>​    简单的解释就是，对任一q属于k-reciprocal nearest neightbors, 求R(q,k/2)； 若R(q,k/2)与R(p,k)的交集数量大于2/3的|R(q,k/2)|，则将R(q,k/2)合并到R(p,k)，得到expanded k-reciprocalnearest neightbors.</p>
<h3 id="Jaccard-Distance"><a href="#Jaccard-Distance" class="headerlink" title="Jaccard Distance"></a>Jaccard Distance</h3><p>​    若probe和gallery的两个图片的k-reciprocal nearest neighbor重叠的越多，可以认为两张图片越近似：</p>
<p><img src="/2019/09/18/Reranking/Jaccard-distance.png" alt></p>
<p>​    可以使用该距离做为<strong>新的度量方式</strong>，但是该方法存在几个缺点：</p>
<p>（1）时间复杂度高：</p>
<p>重新计算距离矩阵的复杂度为<br>$$<br>O((N+M)^2kk)<br>$$<br>N,M分别为probes, galleries的图片数量</p>
<p>计算expanded k-reciprocalnearest neightbors的时间复杂度为：<br>$$<br>O((N+M)(D(N+M)+(N+M)+klog(N+M)+kk/2log(N+M)))<br>$$<br>其中, D为feature的长度，(N+M)是建堆的时间复杂度，kxlog(N+M)是topk的查询复杂度，kxk/2xlog(N+M))是expand的时间复杂度。</p>
<p>ps: 其实个人理解使用修改后的方案（k-reciprocal feature），还是要计算expanded k-reciprocalnearest neightbors，所以k-reciprocal feature并不是针对这点提出的改进。</p>
<p>（2）jaccard distance未考虑top-k中每张图片的权重，但显然排名高的图像权重应该更大</p>
<p>考虑将k-reciprocal nearest neighbor编码为向量，称为k-reciprocal feature</p>
<h3 id="k-reciprocal-feature"><a href="#k-reciprocal-feature" class="headerlink" title="k-reciprocal feature"></a>k-reciprocal feature</h3><p><img src="/2019/09/18/Reranking/Vp.png" alt></p>
<p>即对属于expand k-reciprocal nearest neighbor的编码为1，否则为0，长度为probes+galleries的长度.</p>
<p>接下来，对编码为1的使用指数函数计算相似度：</p>
<p><img src="/2019/09/18/Reranking/weight-V.png" alt><br>  其中公式（8）（9）可以这样理解，对于一个向量，按元素操作，0和非零值取min代表着交集，0和非零值取max 代表着并集，其一阶范数代表这集合得大小。</p>
<h3 id="Local-Query-Expansion"><a href="#Local-Query-Expansion" class="headerlink" title="Local Query Expansion"></a>Local Query Expansion</h3><p>假设相同ID的图片拥有相似的特征，因此可以使用probe的topk对Vp进行修正，注意top-k应该包含了p：</p>
<p><img src="/2019/09/18/Reranking/local-query-expansion.png" alt></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>reranking 主要有3个参数： k1=20, k2=6, lambda_value=0.3</p>
<p>k1是计算k-reciprocal nearest neighbor的k，不宜过大，特别是存在大量只有几张图片的ID时</p>
<p>k2是计算Local Query Expansion的k, 不宜过大，特别是存在大量只有几张图片的ID时，而且一般比k1小</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/18/Reranking/" data-id="cke3gzxbf0002poukn64cawia" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ReID/">ReID</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Image-Classification/">Image Classification</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ojbect-Detection/">Ojbect_Detection</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ReID/">ReID</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Image-Classification-Data-Augmentation/">Image Classification, Data Augmentation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ojbect-Detection/">Ojbect_Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReID/">ReID</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Image-Classification-Data-Augmentation/" style="font-size: 10px;">Image Classification, Data Augmentation</a> <a href="/tags/Ojbect-Detection/" style="font-size: 10px;">Ojbect_Detection</a> <a href="/tags/ReID/" style="font-size: 10px;">ReID</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/08/21/Aboutme/">Aboutme</a>
          </li>
        
          <li>
            <a href="/2020/08/20/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2020/04/30/Data-Augmentations-in-Image-Classification/">Data Augmentations in Image Classification</a>
          </li>
        
          <li>
            <a href="/2019/10/13/map-evaluation of object detection/">Anlysis and implementation of mAP-evaluation of object detection</a>
          </li>
        
          <li>
            <a href="/2019/09/18/Reranking/">Reranking</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Yao<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>